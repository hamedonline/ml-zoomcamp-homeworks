{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning Zoomcamp Homeworks"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Week 3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this homework, we will continue the New York City Airbnb Open Data. You can take it from\r\n",
    "[Kaggle](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv)\r\n",
    "or download from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv)\r\n",
    "if you don't want to sign up to Kaggle.\r\n",
    "\r\n",
    "We'll keep working with the `'price'` variable, and we'll transform it to a classification task."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Features\r\n",
    "\r\n",
    "For the rest of the homework, you'll need to use the features from the previous homework with additional two `'neighbourhood_group'` and `'room_type'`. So the whole feature set will be set as follows:\r\n",
    "\r\n",
    "* `'neighbourhood_group'`,\r\n",
    "* `'room_type'`,\r\n",
    "* `'latitude'`,\r\n",
    "* `'longitude'`,\r\n",
    "* `'price'`,\r\n",
    "* `'minimum_nights'`,\r\n",
    "* `'number_of_reviews'`,\r\n",
    "* `'reviews_per_month'`,\r\n",
    "* `'calculated_host_listings_count'`,\r\n",
    "* `'availability_365'`\r\n",
    "\r\n",
    "Select only them and fill in the missing values with 0."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "\r\n",
    "df = pd.read_csv('data\\AB_NYC_2019.csv')\r\n",
    "\r\n",
    "# column selection\r\n",
    "desired_columns = ['neighbourhood_group', 'room_type', 'latitude', 'longitude', 'price', \r\n",
    "                   'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365']\r\n",
    "df_final = df[desired_columns]\r\n",
    "\r\n",
    "# fill missing values with zero\r\n",
    "df_final = df_final.fillna(0)\r\n",
    "\r\n",
    "print(df_final.isnull().sum())\r\n",
    "\r\n",
    "df_final\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "neighbourhood_group               0\n",
      "room_type                         0\n",
      "latitude                          0\n",
      "longitude                         0\n",
      "price                             0\n",
      "minimum_nights                    0\n",
      "number_of_reviews                 0\n",
      "reviews_per_month                 0\n",
      "calculated_host_listings_count    0\n",
      "availability_365                  0\n",
      "dtype: int64\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>room_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Private room</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Private room</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48890</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Private room</td>\n",
       "      <td>40.67853</td>\n",
       "      <td>-73.94995</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48891</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Private room</td>\n",
       "      <td>40.70184</td>\n",
       "      <td>-73.93317</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48892</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>40.81475</td>\n",
       "      <td>-73.94867</td>\n",
       "      <td>115</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48893</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Shared room</td>\n",
       "      <td>40.75751</td>\n",
       "      <td>-73.99112</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48894</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Private room</td>\n",
       "      <td>40.76404</td>\n",
       "      <td>-73.98933</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48895 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      neighbourhood_group        room_type  latitude  longitude  price  \\\n",
       "0                Brooklyn     Private room  40.64749  -73.97237    149   \n",
       "1               Manhattan  Entire home/apt  40.75362  -73.98377    225   \n",
       "2               Manhattan     Private room  40.80902  -73.94190    150   \n",
       "3                Brooklyn  Entire home/apt  40.68514  -73.95976     89   \n",
       "4               Manhattan  Entire home/apt  40.79851  -73.94399     80   \n",
       "...                   ...              ...       ...        ...    ...   \n",
       "48890            Brooklyn     Private room  40.67853  -73.94995     70   \n",
       "48891            Brooklyn     Private room  40.70184  -73.93317     40   \n",
       "48892           Manhattan  Entire home/apt  40.81475  -73.94867    115   \n",
       "48893           Manhattan      Shared room  40.75751  -73.99112     55   \n",
       "48894           Manhattan     Private room  40.76404  -73.98933     90   \n",
       "\n",
       "       minimum_nights  number_of_reviews  reviews_per_month  \\\n",
       "0                   1                  9               0.21   \n",
       "1                   1                 45               0.38   \n",
       "2                   3                  0               0.00   \n",
       "3                   1                270               4.64   \n",
       "4                  10                  9               0.10   \n",
       "...               ...                ...                ...   \n",
       "48890               2                  0               0.00   \n",
       "48891               4                  0               0.00   \n",
       "48892              10                  0               0.00   \n",
       "48893               1                  0               0.00   \n",
       "48894               7                  0               0.00   \n",
       "\n",
       "       calculated_host_listings_count  availability_365  \n",
       "0                                   6               365  \n",
       "1                                   2               355  \n",
       "2                                   1               365  \n",
       "3                                   1               194  \n",
       "4                                   1                 0  \n",
       "...                               ...               ...  \n",
       "48890                               2                 9  \n",
       "48891                               2                36  \n",
       "48892                               1                27  \n",
       "48893                               6                 2  \n",
       "48894                               1                23  \n",
       "\n",
       "[48895 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question #1\r\n",
    "\r\n",
    "What is the most frequent observation (mode) for the column `'neighbourhood_group'`?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# answer to question #1\r\n",
    "\r\n",
    "df_final['neighbourhood_group'].value_counts()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Manhattan        21661\n",
       "Brooklyn         20104\n",
       "Queens            5666\n",
       "Bronx             1091\n",
       "Staten Island      373\n",
       "Name: neighbourhood_group, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, 'Manhattan' is the most frequent value in 'neighbourhood_group' column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split the data\r\n",
    "\r\n",
    "* Split your data in train/val/test sets, with 60%/20%/20% distribution.\r\n",
    "* Use Scikit-Learn for that (the `train_test_split` function) and set the seed to 42.\r\n",
    "* Make sure that the target value ('price') is not in your dataframe.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "random_seed = 42\r\n",
    "df_train_full, df_test = train_test_split(df_final, test_size=0.2, random_state=random_seed)\r\n",
    "df_train, df_valid     = train_test_split(df_train_full, test_size=0.25, random_state=random_seed)\r\n",
    "\r\n",
    "print(len(df_final), len(df_train), len(df_valid), len(df_test))\r\n",
    "\r\n",
    "del df_train['price']\r\n",
    "del df_valid['price']\r\n",
    "del df_test['price']\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "48895 29337 9779 9779\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question #2\r\n",
    "\r\n",
    "* Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your train dataset.\r\n",
    "   * In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset.\r\n",
    "* What are the two features that have the biggest correlation in this dataset?\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# answer to question #2\r\n",
    "\r\n",
    "columns_numerical = df_train.select_dtypes(include=['int64', 'float64']).columns.to_list()\r\n",
    "\r\n",
    "corr_matrix = []\r\n",
    "for column in columns_numerical:\r\n",
    "    corr_matrix.append(df_train[columns_numerical].corrwith(df_train[column]).to_numpy())\r\n",
    "\r\n",
    "df_corr_matrix = pd.DataFrame(corr_matrix)\r\n",
    "print('Correlation Matrix:\\n', df_corr_matrix, '\\n')\r\n",
    "\r\n",
    "\r\n",
    "corr_dict = dict()\r\n",
    "for i in range(len(corr_matrix)):\r\n",
    "    for j in range(i+1, len(corr_matrix)):\r\n",
    "        corr_dict[corr_matrix[i][j]] = (i,j)\r\n",
    "\r\n",
    "corr_positive_dict = dict((k, v) for k, v in corr_dict.items() if k >= 0.0)\r\n",
    "corr_negative_dict = dict((k, v) for k, v in corr_dict.items() if k < 0.0)\r\n",
    "\r\n",
    "\r\n",
    "highest_positive_corr = max(corr_positive_dict.keys())\r\n",
    "highest_negative_corr = min(min(corr_negative_dict.keys()), 0)\r\n",
    "highest_corr = max(highest_positive_corr, abs(highest_negative_corr))\r\n",
    "\r\n",
    "if highest_corr in corr_positive_dict.keys():\r\n",
    "    highest_corr_index = corr_positive_dict[highest_corr]\r\n",
    "else:\r\n",
    "    highest_corr_index = corr_negative_dict[-1*(highest_corr)]\r\n",
    "\r\n",
    "print('Highest Correlated Columns: ',\r\n",
    "      (columns_numerical[highest_corr_index[0]], columns_numerical[highest_corr_index[1]]),\r\n",
    "      ': ', highest_corr)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Correlation Matrix:\n",
      "           0         1         2         3         4         5         6\n",
      "0  1.000000  0.080301  0.027441 -0.006246 -0.007159  0.019375 -0.005891\n",
      "1  0.080301  1.000000 -0.060660  0.055084  0.134642 -0.117041  0.083666\n",
      "2  0.027441 -0.060660  1.000000 -0.076020 -0.120703  0.118647  0.138901\n",
      "3 -0.006246  0.055084 -0.076020  1.000000  0.590374 -0.073167  0.174477\n",
      "4 -0.007159  0.134642 -0.120703  0.590374  1.000000 -0.048767  0.165376\n",
      "5  0.019375 -0.117041  0.118647 -0.073167 -0.048767  1.000000  0.225913\n",
      "6 -0.005891  0.083666  0.138901  0.174477  0.165376  0.225913  1.000000 \n",
      "\n",
      "Highest Correlated Columns:  ('number_of_reviews', 'reviews_per_month') :  0.5903739015971651\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make price binary\r\n",
    "\r\n",
    "* We need to turn the price variable from numeric into binary.\r\n",
    "* Let's create a variable `above_average` which is `1` if the price is above (or equal to) `152`.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df_final['above_average'] = pd.Series(df_final['price'] >= 152).astype(int)\r\n",
    "\r\n",
    "\r\n",
    "random_seed = 42\r\n",
    "df_train_full, df_test = train_test_split(df_final, test_size=0.2, random_state=random_seed)\r\n",
    "df_train, df_valid     = train_test_split(df_train_full, test_size=0.25, random_state=random_seed)\r\n",
    "\r\n",
    "del df_train['price']\r\n",
    "del df_valid['price']\r\n",
    "del df_test['price']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question #3\r\n",
    "\r\n",
    "* Calculate the mutual information score with the (binarized) price for the two categorical variables that we have. Use the training set only.\r\n",
    "* Which of these two variables has bigger score?\r\n",
    "* Round it to 2 decimal digits using `round(score, 2)`\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# answer to question #3\r\n",
    "\r\n",
    "from sklearn.metrics import mutual_info_score\r\n",
    "from IPython.display import display\r\n",
    "\r\n",
    "\r\n",
    "columns_categorical = df_train.select_dtypes(include=['object', 'bool']).columns.to_list()\r\n",
    "\r\n",
    "def calculate_mi(series):\r\n",
    "    return mutual_info_score(series, df_train['above_average'])\r\n",
    "\r\n",
    "df_train_mi = df_train[columns_categorical].apply(calculate_mi)\r\n",
    "df_train_mi = df_train_mi.sort_values(ascending=False).to_frame(name='Mutual Information')\r\n",
    "\r\n",
    "\r\n",
    "display(df_train_mi)\r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mutual Information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>room_type</th>\n",
       "      <td>0.143226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <td>0.046506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Mutual Information\n",
       "room_type                      0.143226\n",
       "neighbourhood_group            0.046506"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(round(df_train_mi['Mutual Information']['room_type'], 2))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.14\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "'room_type' column has bigger mutual information score."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question #4\r\n",
    "\r\n",
    "* Now let's train a logistic regression\r\n",
    "* Remember that we have two categorical variables in the data. Include them using one-hot encoding.\r\n",
    "* Fit the model on the training dataset.\r\n",
    "   * To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\r\n",
    "   * `model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42)`\r\n",
    "* Calculate the accuracy on the validation dataset and rount it to 2 decimal digits."
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# answer to question #4\r\n",
    "\r\n",
    "from sklearn.feature_extraction import DictVectorizer\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from warnings import simplefilter\r\n",
    "# ignore all warnings\r\n",
    "simplefilter(action='ignore')\r\n",
    "\r\n",
    "\r\n",
    "y_train = df_train['above_average'].to_numpy()\r\n",
    "y_valid = df_valid['above_average'].to_numpy()\r\n",
    "y_test  = df_test['above_average'].to_numpy()\r\n",
    "\r\n",
    "del df_train['above_average']\r\n",
    "del df_valid['above_average']\r\n",
    "del df_test['above_average']\r\n",
    "\r\n",
    "\r\n",
    "train_dict = df_train[columns_categorical + columns_numerical].to_dict(orient='records')\r\n",
    "dv = DictVectorizer(sparse=False)\r\n",
    "dv.fit(train_dict)\r\n",
    "\r\n",
    "X_train = dv.transform(train_dict)\r\n",
    "model = LogisticRegression(solver='lbfgs', C=1.0, random_state=random_seed)\r\n",
    "model.fit(X_train, y_train)\r\n",
    "\r\n",
    "val_dict = df_valid[columns_categorical + columns_numerical].to_dict(orient='records')\r\n",
    "X_valid = dv.transform(val_dict)\r\n",
    "\r\n",
    "y_pred = model.predict_proba(X_valid)[:, 1]\r\n",
    "target_pred = y_pred > 0.5\r\n",
    "\r\n",
    "pred_score = (y_valid == target_pred).mean()\r\n",
    "print('<<Prediction Score>>\\n > Actual: {}\\n > Rounded: {}\\n'.format(\r\n",
    "    pred_score, round(pred_score, 2)))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<<Prediction Score>>\n",
      " > Actual: 0.7864812353001329\n",
      " > Rounded: 0.79\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question #5\r\n",
    "\r\n",
    "* We have 9 features: 7 numerical features and 2 categorical.\r\n",
    "* Let's find the least useful one using the *feature elimination* technique.\r\n",
    "* Train a model with all these features (using the same parameters as in Q4).\r\n",
    "* Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\r\n",
    "* For each feature, calculate the difference between the original accuracy and the accuracy without the feature. \r\n",
    "* Which of following feature has the smallest difference? \r\n",
    "   * `neighbourhood_group`\r\n",
    "   * `room_type` \r\n",
    "   * `number_of_reviews`\r\n",
    "   * `reviews_per_month`\r\n",
    "\r\n",
    "> **note**: the difference doesn't have to be positive\r\n"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# answer to question #5\r\n",
    "\r\n",
    "def get_elimination_data(drop_columns: list, dataset: str):\r\n",
    "    if   dataset == 'train': return df_train.drop(drop_columns, axis=1)\r\n",
    "    elif dataset == 'valid': return df_valid.drop(drop_columns, axis=1)\r\n",
    "    elif dataset == 'test':  return df_test.drop(drop_columns, axis=1)\r\n",
    "    else: return\r\n",
    "\r\n",
    "\r\n",
    "feature_elimination_difference_dict = {}\r\n",
    "longest_column_name_length = max([len(column) for column in df_train.columns.to_list()])\r\n",
    "print('<<Score Status After Feature Elimination>>\\nDropped Column'+' '*(longest_column_name_length+2-len('Dropped Column'))+'Score\\tDiff.')\r\n",
    "for column in df_train.columns.to_list():\r\n",
    "    train_data = get_elimination_data(drop_columns=[column], dataset='train')\r\n",
    "    train_dict = train_data.to_dict(orient='records')\r\n",
    "\r\n",
    "    dv = DictVectorizer(sparse=False)\r\n",
    "    dv.fit(train_dict)\r\n",
    "\r\n",
    "    X_train = dv.transform(train_dict)\r\n",
    "    model = LogisticRegression(solver='lbfgs', C=1.0, random_state=random_seed,)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "\r\n",
    "    valid_data = get_elimination_data(drop_columns=[column], dataset='valid')\r\n",
    "    val_dict = valid_data.to_dict(orient='records')\r\n",
    "    X_valid = dv.transform(val_dict)\r\n",
    "\r\n",
    "    y_pred = model.predict_proba(X_valid)[:, 1]\r\n",
    "    target_pred = y_pred > 0.5\r\n",
    "    score_after_elimination = (y_valid == target_pred).mean()\r\n",
    "\r\n",
    "    score_difference = (pred_score - score_after_elimination)\r\n",
    "    feature_elimination_difference_dict[column] = score_difference\r\n",
    "    \r\n",
    "    print('{} {} {:.3f} \\t {:+.2g}'.format(column, ' '*(longest_column_name_length-len(column)), score_after_elimination, score_difference))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<<Score Status After Feature Elimination>>\n",
      "Dropped Column                  Score\tDiff.\n",
      "neighbourhood_group             0.751 \t +0.035\n",
      "room_type                       0.715 \t +0.071\n",
      "latitude                        0.786 \t +0.0001\n",
      "longitude                       0.787 \t -0.00031\n",
      "minimum_nights                  0.786 \t +0.00082\n",
      "number_of_reviews               0.787 \t -0.00051\n",
      "reviews_per_month               0.786 \t +0.00061\n",
      "calculated_host_listings_count  0.787 \t -0.0002\n",
      "availability_365                0.782 \t +0.0049\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print('Column Elimination Effect on Classification Score (Least to Most - Global)')\r\n",
    "print(pd.Series(feature_elimination_difference_dict).abs().sort_values(ascending=True), '\\n')\r\n",
    "\r\n",
    "only_interested_in = ['neighbourhood_group', 'room_type', 'number_of_reviews', 'reviews_per_month']\r\n",
    "print('Column Elimination Effect on Classification Score (Least to Most - Only Question Columns)')\r\n",
    "print(pd.Series(feature_elimination_difference_dict)[only_interested_in].abs().sort_values(ascending=True))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Column Elimination Effect on Classification Score (Least to Most - Global)\n",
      "latitude                          0.000102\n",
      "calculated_host_listings_count    0.000205\n",
      "longitude                         0.000307\n",
      "number_of_reviews                 0.000511\n",
      "reviews_per_month                 0.000614\n",
      "minimum_nights                    0.000818\n",
      "availability_365                  0.004908\n",
      "neighbourhood_group               0.035484\n",
      "room_type                         0.071377\n",
      "dtype: float64 \n",
      "\n",
      "Column Elimination Effect on Classification Score (Least to Most - Only Question Columns)\n",
      "number_of_reviews      0.000511\n",
      "reviews_per_month      0.000614\n",
      "neighbourhood_group    0.035484\n",
      "room_type              0.071377\n",
      "dtype: float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is obvious that among the questioned features, eliminating 'number_of_reviews' column almost would not effect the classification score."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question #6\r\n",
    "\r\n",
    "* For this question, we'll see how to use a linear regression model from Scikit-Learn\r\n",
    "* We'll need to use the original column `'price'`. Apply the logarithmic transformation to this column.\r\n",
    "* Fit the Ridge regression model on the training data.\r\n",
    "* This model has a parameter `alpha`. Let's try the following values: `[0, 0.01, 0.1, 1, 10]`\r\n",
    "* Which of these alphas leads to the best RMSE on the validation set? Round your RMSE scores to 3 decimal digits.\r\n",
    "\r\n",
    "If there are multiple options, select the smallest `alpha`."
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# answer to question #6\r\n",
    "\r\n",
    "import math\r\n",
    "from sklearn.linear_model import Ridge\r\n",
    "\r\n",
    "\r\n",
    "# define regression evaluation metrics\r\n",
    "def mse(y, y_pred):\r\n",
    "    error = 0.0\r\n",
    "    for yt, yp in zip(y, y_pred):\r\n",
    "        error += (yt - yp) ** 2\r\n",
    "    return (error / len(y))\r\n",
    "\r\n",
    "def rmse(y, y_pred):\r\n",
    "    return math.sqrt(mse(y, y_pred))\r\n",
    "\r\n",
    "\r\n",
    "train_dict = df_train.to_dict(orient='records')\r\n",
    "dv = DictVectorizer(sparse=False)\r\n",
    "dv.fit(train_dict)\r\n",
    "X_train  = dv.transform(train_dict)\r\n",
    "val_dict = df_valid.to_dict(orient='records')\r\n",
    "X_valid  = dv.transform(val_dict)\r\n",
    "\r\n",
    "# we use indices of train and valid sets to select corresponding rows from df_final (which holds whole data)\r\n",
    "y_train_reg = np.log1p(df_final['price'].loc[df_train.index])\r\n",
    "y_valid_reg = np.log1p(df_final['price'].loc[df_valid.index])\r\n",
    "\r\n",
    "\r\n",
    "print('<<RMSE Scores for Ridge Regression Model>>\\nalpha\\t\\tScore')\r\n",
    "rmse_scores_dict = {}\r\n",
    "for alpha in [0, 0.01, 0.1, 1, 10]:\r\n",
    "    model = Ridge(alpha=alpha)\r\n",
    "    model.fit(X_train, y_train_reg)\r\n",
    "    y_pred = model.predict(X_valid)\r\n",
    "    rmse_score = rmse(y_valid_reg, y_pred)\r\n",
    "    rmse_scores_dict[alpha] = rmse_score\r\n",
    "    print('{} \\t\\t {:.3f}'.format(alpha, rmse_score))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<<RMSE Scores for Ridge Regression Model>>\n",
      "alpha\t\tScore\n",
      "0 \t\t 0.497\n",
      "0.01 \t\t 0.497\n",
      "0.1 \t\t 0.497\n",
      "1 \t\t 0.497\n",
      "10 \t\t 0.498\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print('RMSE Scores Sorted Lowest to Highest (lower values are better)\\nalpha\\tScore')\r\n",
    "print(pd.Series(rmse_scores_dict).abs().sort_values(ascending=True), '\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE Scores Sorted Lowest to Highest (lower values are better)\n",
      "alpha\tScore\n",
      "0.00     0.497074\n",
      "0.01     0.497117\n",
      "0.10     0.497118\n",
      "1.00     0.497140\n",
      "10.00    0.497887\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Values are close but it looks like alpha=0.0 leads to a slightly lower rmse (better score)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}