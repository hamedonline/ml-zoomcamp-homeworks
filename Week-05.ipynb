{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Zoomcamp Homeworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 5\n",
    "In this homework, we'll use the churn prediction model trained on a smaller set of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #1\n",
    "\n",
    "* Install Pipenv\n",
    "* What's the version of pipenv you installed?\n",
    "* Use `--version` to find out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipenv, version 2020.11.15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# answer to question #1\n",
    "\n",
    "!pipenv --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question #2\n",
    "\n",
    "* Use Pipenv to install Scikit-Learn version 1.0\n",
    "* What's the first hash for scikit-learn you get in Pipfile.lock?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer to question #2:\n",
    "\n",
    "All you need to do is to look up \"Pipfile.lock\" file in the folder you created virtual environment.<br>\n",
    "Opening the file with your favorite editor, you'll find \"scikit-learn\" json key with \"hashes\" sub-key (about 25 hashesh in my case). The first hash value is:<br>\n",
    "sha256:121f78d6564000dc5e968394f45aac87981fcaaf2be40cfcd8f07b2baa1e1829"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "We've prepared a dictionary vectorizer and a model.\n",
    "\n",
    "They were trained (roughly) using this code:\n",
    "\n",
    "```\n",
    "features = ['tenure', 'monthlycharges', 'contract']\n",
    "dicts = df[features].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X = dv.fit_transform(dicts)\n",
    "\n",
    "model = LogisticRegression().fit(X, y)\n",
    "```\n",
    "\n",
    "> **Note**: You don't need to train the model. This code is just for your reference.\n",
    "\n",
    "And then saved with Pickle. Download them:\n",
    "\n",
    "* [DictVectorizer](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/05-deployment/homework/dv.bin?raw=true)\n",
    "* [LogisticRegression](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/05-deployment/homework/model1.bin?raw=true)\n",
    "\n",
    "With wget:\n",
    "\n",
    "```bash\n",
    "PREFIX=https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/course-zoomcamp/05-deployment/homework\n",
    "wget $PREFIX/model1.bin\n",
    "wget $PREFIX/dv.bin\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #3\n",
    "\n",
    "Let's use these models!\n",
    "\n",
    "* Write a script for loading these models with pickle\n",
    "* Score this customer:\n",
    "\n",
    "```json\n",
    "{\"contract\": \"two_year\", \"tenure\": 12, \"monthlycharges\": 19.7}\n",
    "```\n",
    "\n",
    "What's the probability that this customer is churning? \n",
    "\n",
    "If you're getting errors when unpickling the files, check their checksum:\n",
    "\n",
    "```bash\n",
    "$ md5sum model1.bin dv.bin\n",
    "5868e129bfbb309ba60bf750263afab1  model1.bin\n",
    "c49b69f8a5a3c560882ff5daa3c0ff4d  dv.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Customer Churning? False\n",
      "Churn Probability: 0.115\n"
     ]
    }
   ],
   "source": [
    "# answer to question #3\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "def load_model(path_to_model, path_to_dv):\n",
    "    with open(path_to_model, 'rb') as model_file, open(path_to_dv, 'rb') as dv_file:\n",
    "        model = pickle.load(model_file)\n",
    "        dv = pickle.load(dv_file)\n",
    "    return model, dv\n",
    "\n",
    "def predict_churn(model, dv, customer_data):\n",
    "    X = dv.transform([customer_data])\n",
    "    y_pred = model.predict_proba(X)[0, 1]\n",
    "    is_churning = y_pred >= 0.5\n",
    "\n",
    "    result = {\n",
    "        'churn': bool(is_churning),\n",
    "        'churn_probability': float(y_pred)\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "data = {\"contract\": \"two_year\", \"tenure\": 12, \"monthlycharges\": 19.7}\n",
    "model, dv = load_model(path_to_model='virtual-envs\\hw05\\models\\model1.bin',\n",
    "                       path_to_dv='virtual-envs\\hw05\\models\\dv.bin')\n",
    "prediction_result = predict_churn(model=model, dv=dv, customer_data=data)\n",
    "print('Is Customer Churning? {}\\nChurn Probability: {}'.format(prediction_result['churn'], round(prediction_result['churn_probability'], 3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #4\n",
    "\n",
    "Now let's serve this model as a web service\n",
    "\n",
    "* Install Flask and Gunicorn (or waitress, if you're on Windows)\n",
    "* Write Flask code for serving the model\n",
    "* Now score this customer using `requests`:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "customer = {\"contract\": \"two_year\", \"tenure\": 1, \"monthlycharges\": 10}\n",
    "requests.post(url, json=customer).json()\n",
    "```\n",
    "\n",
    "What's the probability that this customer is churning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # answer to question #4\n",
    "# ## the following lines must be stored in churn.py file which should be running in the background using command line \"python churn.py\" or \"python -m churn\"\n",
    "\n",
    "\n",
    "# import pickle\n",
    "# from flask import Flask, request, jsonify\n",
    "# from waitress import serve\n",
    "\n",
    "\n",
    "# def load_model(path_to_model, path_to_dv):\n",
    "#     with open(path_to_model, 'rb') as model_file, open(path_to_dv, 'rb') as dv_file:\n",
    "#         model = pickle.load(model_file)\n",
    "#         dv = pickle.load(dv_file)\n",
    "#     return model, dv\n",
    "\n",
    "\n",
    "# def predict_churn(model, dv, customer_data):\n",
    "#     X = dv.transform([customer_data])\n",
    "#     y_pred = model.predict_proba(X)[0, 1]\n",
    "#     is_churning = y_pred >= 0.5\n",
    "\n",
    "#     result = {\n",
    "#         'churn': bool(is_churning),\n",
    "#         'churn_probability': float(y_pred)\n",
    "#     }\n",
    "#     return jsonify(result)\n",
    "\n",
    "\n",
    "# app = Flask('churn')\n",
    "# @app.route('/churn/predict', methods=['POST'])\n",
    "# def predict():\n",
    "#     customer_data = request.get_json()\n",
    "\n",
    "#     model, dv = load_model(path_to_model='models\\model1.bin',\n",
    "#                            path_to_dv='models\\dv.bin')\n",
    "#     prediction_result = predict_churn(\n",
    "#         model=model, dv=dv, customer_data=customer_data)\n",
    "\n",
    "#     return prediction_result\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # app.run(debug=True, host='0.0.0.0', port=9696)\n",
    "#     serve(app, host='0.0.0.0', port=9696)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'churn': True, 'churn_probability': 0.9988892771007961}\n",
      "Is Customer Churning? True\n",
      "Churn Probability: 0.9989\n"
     ]
    }
   ],
   "source": [
    "# answer to question #4 (cont.)\n",
    "\n",
    "import requests\n",
    "\n",
    "api_url = \"http://localhost:9696/churn/predict\"\n",
    "customer_data = {\n",
    "    \"contract\": \"two_year\",\n",
    "    \"tenure\": 1,\n",
    "    \"monthlycharges\": 10\n",
    "}\n",
    "\n",
    "api_response = requests.post(url=api_url, json=customer_data).json()\n",
    "print(api_response)\n",
    "print('Is Customer Churning? {}\\nChurn Probability: {}'.format(api_response['churn'], round(api_response['churn_probability'], 4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker\n",
    "\n",
    "Install [Docker](06-docker.md). We will use it for the next two questions.\n",
    "\n",
    "For these questions, I prepared a base image: `agrigorev/zoomcamp-model:3.8.12-slim`. \n",
    "You'll need to use it (see Question 5 for an example).\n",
    "\n",
    "This image is based on `python:3.8.12-slim` and has a logistic regression model \n",
    "(a different one) as well a dictionary vectorizer inside. \n",
    "\n",
    "This is how the Dockerfile for this image looks like:\n",
    "\n",
    "```docker \n",
    "FROM python:3.8.12-slim\n",
    "WORKDIR /app\n",
    "COPY [\"model2.bin\", \"dv.bin\", \"./\"]\n",
    "```\n",
    "\n",
    "I already built it and then pushed it to [`agrigorev/zoomcamp-model:3.8.12-slim`](https://hub.docker.com/r/agrigorev/zoomcamp-model).\n",
    "\n",
    "> **Note**: You don't need to build this docker image, it's just for your reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #5\n",
    "\n",
    "Now create your own Dockerfile based on the image I prepared.\n",
    "\n",
    "It should start like that:\n",
    "\n",
    "```docker\n",
    "FROM agrigorev/zoomcamp-model:3.8.12-slim\n",
    "# add your stuff here\n",
    "```\n",
    "\n",
    "Now complete it:\n",
    "\n",
    "* Install all the dependencies form the Pipenv file\n",
    "* Copy your Flask script\n",
    "* Run it with gunicorn \n",
    "\n",
    "\n",
    "When you build your image, what's the image id for `agrigorev/zoomcamp-model:3.8.12-slim`?\n",
    "\n",
    "Look at the first step of your build log. It should look something like that:\n",
    "\n",
    "```\n",
    "$ docker some-command-for-building\n",
    "Sending build context to Docker daemon  2.048kB\n",
    "Step 1/N : FROM agrigorev/zoomcamp-model:3.8.12-slim\n",
    " ---> XXXXXXXXXXXX\n",
    "Step 2/N : ....\n",
    "```\n",
    "\n",
    "You need this `XXXXXXXXXXXX`.\n",
    "\n",
    "Alternatively, you can get this information when running `docker images` - it'll be in the \"IMAGE ID\" column.\n",
    "Submitting DIGEST (long string starting with \"sha256\") is also fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer to question #5:<br>\n",
    "IMAGE ID: f0f43f7bc6e0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question #6\n",
    "\n",
    "Let's run your docker container!\n",
    "\n",
    "After running it, score the same customer:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "customer = {\"contract\": \"two_year\", \"tenure\": 12, \"monthlycharges\": 10}\n",
    "requests.post(url, json=customer).json()\n",
    "```\n",
    "\n",
    "What's the probability that this customer is churning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'churn': False, 'churn_probability': 0.32940789808151005}\n",
      "Is Customer Churning? False\n",
      "Churn Probability: 0.329\n"
     ]
    }
   ],
   "source": [
    "# answer to question #6\n",
    "\n",
    "docker_instance_url = \"http://localhost:9000/churn/predict\"\n",
    "customer2_data = {\n",
    "    \"contract\": \"two_year\",\n",
    "    \"tenure\": 12,\n",
    "    \"monthlycharges\": 10\n",
    "}\n",
    "\n",
    "api_response_docker = requests.post(url=docker_instance_url, json=customer2_data).json()\n",
    "print(api_response_docker)\n",
    "print('Is Customer Churning? {}\\nChurn Probability: {}'.format(api_response_docker['churn'], round(api_response_docker['churn_probability'], 3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above response is received from the running docker instance and the churn probability is: 0.3294<br><br>\n",
    "Notice that this time around, port 9000 of the host machine is utilized to map the running app on port 9696 of the container:<br>\n",
    "_docker run -it --rm -p 9000:9696 churn-predict_<br><br>\n",
    "The \"Dockerfie\" for instance has following lines:<br>\n",
    "\n",
    "```Dockerfile\n",
    "FROM python:3.8.12-slim\n",
    "\n",
    "RUN pip install pipenv\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY [\"Pipfile\", \"Pipfile.lock\", \"./\"]\n",
    "\n",
    "RUN pipenv install --system --deploy\n",
    "\n",
    "COPY [\"churn.py\", \"./\"]\n",
    "\n",
    "COPY [\"models/model1.bin\", \"models/dv.bin\", \"models/\"]\n",
    "\n",
    "EXPOSE 9696\n",
    "\n",
    "ENTRYPOINT [\"python\", \"churn.py\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f5ac38789241b4bb81b8932c8570b25ca6d45fbb16cf755cff1dd5201e7e529"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('hw05-KBu8Ds8V': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
